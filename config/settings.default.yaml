DB_ENGINE: "postgresql+psycopg2://grimoire:secretpassword@127.0.0.1:5430/grimoire"
DEBUG: False
LOG_PROMPTS: False
LOG_FILES: False
AUTH_KEY: ""
ENCRYPTION_KEY: !env ENCRYPTION_KEY
prefer_gpu: False
match_distance: 80

redis:
  REDIS_HOST: "127.0.0.1:6370" # For Sentinel, separate hosts with ,
  REDIS_SENTINEL: False
  SENTINEL_MASTER_NAME: ""
  REDIS_TLS: False
  CACHE_EXPIRE_TIME: 86400

summarization_api:
  backend: GenericOAI
  model: "" # Used when inference has multiple models/loras, if empty first found name is used
  url: !env SUMMARIZATION_API_URL
  auth_key: !env SUMMARIZATION_API_AUTH
  context_length: 4096
  system_sequence: ""
  system_suffix: ""
  input_sequence: "### Instruction:\n"
  input_suffix: ""
  output_sequence: "\n### Response:\n"
  output_suffix: ""
  first_output_sequence: ""
  last_output_sequence: ""
  bos_token: "<s>"

summarization:
  prompt: "{system_sequence}{previous_summary}{messages}{system_suffix}\n{input_sequence}Describe {term}.{input_suffix}{output_sequence}"
  limit_rate: 1
  max_tokens: 300
  params: {'min_p': 0.1, 'rep_pen': 1.0, 'temperature': 0.6, 'stop': ["</s>"], 'stop_sequence': ["</s>"]}

tokenization:
  prefer_local_tokenizer: True
  local_tokenizer: "oobabooga/llama-tokenizer"

secondary_database:
  enabled: False
  db_engine: "postgresql+psycopg2://user:password@database_url:5430/database_name"
  message_encryption: "aesgcm"
  encryption_key: !env SECONDARY_ENCRYPTION_KEY